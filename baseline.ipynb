{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import *\n",
    "import math \n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import operator\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "from datetime import *\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score,f1_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    "\n",
    "def load_variavle(filename):\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y,pred):\n",
    "    return roc_auc_score(y, pred)\n",
    "\n",
    "def f1(y,pred):\n",
    "    return f1_score(y, pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feature(df):\n",
    "    create_fe = list()\n",
    "    col = list()\n",
    "\n",
    "    create_fe.append(len(df))\n",
    "    create_fe.append(len(df.drop_duplicates()))\n",
    "    col.append('data_len')\n",
    "    col.append('data_drop_dup_len')\n",
    "    for i in df.columns:\n",
    "        if i!='设备类型':\n",
    "            create_fe.append(len(df[i].unique()))\n",
    "            create_fe.append(df[i].max())\n",
    "            create_fe.append(df[i].min())\n",
    "#             create_fe.append(df[i].max()-df[i].min())        \n",
    "            create_fe.append(df[i].sum())\n",
    "            create_fe.append(df[i].mean())\n",
    "            create_fe.append(df[i].std())\n",
    "#             create_fe.append(df[i].std()/df[i].mean())  \n",
    "#             create_fe.append(df[i].skew())\n",
    "            \n",
    "            col.append(i+'_unique_len')\n",
    "            col.append(i+'_max')\n",
    "            col.append(i+'_min')\n",
    "#             col.append(i+'max_min_sub')\n",
    "            col.append(i+'_sum')\n",
    "            col.append(i+'_mean')\n",
    "            col.append(i+'_std')\n",
    "#             col.append(i+'std_mean_sub')\n",
    "#             col.append(i+'_skew')\n",
    "        else:\n",
    "            create_fe.append(df[i].max())\n",
    "            col.append(i+'_')\n",
    "    return create_fe,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_uid = os.listdir('../data/data_train/')\n",
    "test_uid = os.listdir('../data/data_test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    shebei = {'ZV41153':0, 'ZV55eec':1, 'ZV75a42':2, \n",
    "          'ZV7e8e3':3, 'ZV90b78':4, 'ZVc1d93':5, 'ZVe0672':6}\n",
    "    try:\n",
    "        train_all_fe =load_variavle('../data/train_fe_v3.pkl')\n",
    "        test_all_fe =load_variavle('../data/test_fe_v3.pkl')\n",
    "    except:\n",
    "        # trin feature\n",
    "        train_all_fe = list()\n",
    "        for i in tqdm(train_uid):\n",
    "            df = pd.read_csv('../data/data_train/'+i)\n",
    "            df['设备类型'] = df['设备类型'].map(shebei)\n",
    "            df,col  = create_feature(df)\n",
    "            train_all_fe.append(df)\n",
    "        train_all_fe = pd.DataFrame(train_all_fe,columns=col)\n",
    "        save_variable(train_all_fe,'../data/train_fe_v3.pkl')\n",
    "        # test feature\n",
    "        test_all_fe = list()\n",
    "        for i in tqdm(test_uid):\n",
    "            df = pd.read_csv('../data/data_test/'+i)\n",
    "            df['设备类型'] = df['设备类型'].map(shebei)\n",
    "            df,col = create_feature(df)\n",
    "            test_all_fe.append(df)\n",
    "        test_all_fe = pd.DataFrame(test_all_fe,columns=col)\n",
    "        save_variable(test_all_fe,'../data/test_fe_v3.pkl')\n",
    "    return train_all_fe,test_all_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69900/69900 [10:22<00:00, 112.33it/s]\n",
      "100%|██████████| 69973/69973 [10:23<00:00, 112.22it/s]\n"
     ]
    }
   ],
   "source": [
    "train_all_fe,test_all_fe = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('../data/train_labels.csv')\n",
    "label.columns = ['uid','label']\n",
    "\n",
    "train_all_fe['uid'] = train_uid\n",
    "train = train_all_fe.merge(label,on = ['uid'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['uid','label'],axis=1)\n",
    "y_train = train['label']\n",
    "X_test = test_all_fe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 5\n",
    "skf = StratifiedKFold(n_splits = K, shuffle = True ,random_state=267)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  0\n",
      "1.0379387003899558\n",
      "[0]\ttrain-auc:0.643731\teval-auc:0.629722\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "\n",
      "Fold  1\n",
      "1.0379751448667955\n",
      "[0]\ttrain-auc:0.643726\teval-auc:0.631077\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "\n",
      "Fold  2\n",
      "1.0379751448667955\n",
      "[0]\ttrain-auc:0.638461\teval-auc:0.635575\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "\n",
      "Fold  3\n",
      "1.0379751448667955\n",
      "[0]\ttrain-auc:0.640716\teval-auc:0.638054\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n",
      "\n",
      "Fold  4\n",
      "1.0379373177842566\n",
      "[0]\ttrain-auc:0.640286\teval-auc:0.63377\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 200 rounds.\n"
     ]
    }
   ],
   "source": [
    "xgb_pred_te_all = 0\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_train,y_train)):\n",
    "    \n",
    "    y_tr, y_val = y_train.iloc[train_index].copy(), y_train.iloc[test_index].copy()\n",
    "    X_tr, X_val= X_train.iloc[train_index,:].copy(), X_train.iloc[test_index,:].copy()\n",
    "    print( \"\\nFold \", i)\n",
    "\n",
    "    xgb_tr = xgb.DMatrix(X_tr, y_tr)\n",
    "    xgb_val = xgb.DMatrix(X_val, y_val)\n",
    "    xgb_te = xgb.DMatrix(X_test)\n",
    "    xgb_params = {\"objective\": 'binary:logistic',\n",
    "                  \"booster\" : \"gbtree\",\n",
    "                  \"eta\": 0.05,\n",
    "                   \"subsample\": 0.85,\n",
    "                  'eval_metric':'auc',\n",
    "                  \"colsample_bytree\": 0.86,\n",
    "                  'gpu_id':0,                        \n",
    "                  \"thread\":-1,\n",
    "                  \"seed\": 666\n",
    "                  }\n",
    "    print(np.sum(y_tr==0)/np.sum(y_tr==1))\n",
    "    watchlist = [(xgb_tr, 'train'), (xgb_val, 'eval')]\n",
    "    xgb_model =xgb.train(xgb_params,\n",
    "                 xgb_tr,\n",
    "                 num_boost_round = 1,\n",
    "                 evals =watchlist, \n",
    "                 verbose_eval=200,\n",
    "                 early_stopping_rounds=200)\n",
    "\n",
    "    pred_te = xgb_model.predict(xgb_te,ntree_limit=xgb_model.best_ntree_limit)\n",
    "    xgb_pred_te_all = xgb_pred_te_all + pred_te / K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'ID':test_uid})\n",
    "sub['Label'] = xgb_pred_te_all\n",
    "sub = sub.sort_values('Label',ascending=False).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[sub.index<34001,'Label'] = 1\n",
    "sub.loc[sub.index>=34001,'Label'] = 0\n",
    "sub['Label'] = sub['Label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../submit/DCIC_sub.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
